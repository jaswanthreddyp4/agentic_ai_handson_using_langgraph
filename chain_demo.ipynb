{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain\n",
    " we will build a chain that will combine few core concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "### lets make a simple chain that combines 4 key components\n",
    " 1. using chat messages in our graph\n",
    " 2. using chat models\n",
    " 3. binding tools to our LLM\n",
    " 4. executing tool calls in our graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet langchain_ibm ibm-watson-machine-learning langchain_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messages\n",
    "### chat models can use \"messages\" , which captures different roles within a convo(say role might be human , model)\n",
    "### Langchain supports various message types , including \"HumanMessage\",\"AIMessage\",\"SystemMessage\", and \"ToolMessage\"\n",
    "### These represents a message from the user, chat model,for chat model to instruct behaviour,and from a tool call\n",
    "### lets create a list of messages , each ,essage can be supplied with few things:\n",
    " 1. \"content\"-content of message\n",
    " 2. \"name\"-who is creating message(model/human..etc)\n",
    " 3. \"response_metadata\"-dict of metadata that is specific to each model provider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean spring framework?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: jas\n",
      "\n",
      "Yes, that's right.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: jas\n",
      "\n",
      "I want to learn about dependency injection and circular dependency in particular\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean spring framework?\", name=\"Model\")]\n",
    "messages.extend([HumanMessage(content=f\"Yes, that's right.\", name=\"jas\")])\n",
    "messages.extend([AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\")])\n",
    "messages.extend([HumanMessage(content=f\"I want to learn about dependency injection and circular dependency in particular\", name=\"jas\")])\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "\n",
    "[Chat models](https://platform.openai.com/docs/guides/gpt) can use a sequence of message as input and support message roles, as discussed above.\n",
    "\n",
    "There are many to choose from!\n",
    "\n",
    "I am using model from watsonX platform(since i have access) , you can try using any model of your wish\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ibm import ChatWatsonx, WatsonxLLM\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "\n",
    "credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": \"LFzc1O7mM0I_Tz2pJmkKjFt-zyYL_U3JLnAjq5MTzay4\"\n",
    "}\n",
    "\n",
    "project_id = \"4af85c47-e2f4-4ffc-af1e-6d8fba82349e\"\n",
    "api_key = credentials.get(\"apikey\")\n",
    "project_url = credentials.get(\"url\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configure LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatWatsonx(\n",
    "    model_id=\"ibm/granite-3-2-8b-instruct\", \n",
    "    url=credentials.get(\"url\"),\n",
    "    apikey=credentials.get(\"apikey\"),\n",
    "    project_id=project_id,\n",
    "    params={\n",
    "        GenParams.DECODING_METHOD: \"sample\",\n",
    "        GenParams.TEMPERATURE: 0.7\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=llm.invoke(messages)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We gave chat messages , now our chat model goes through this chat message conversation depending on role and answer the user query with help of context from messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content=\"Sure, I'd be happy to explain these concepts in the context of Ocean Spring Framework.\\n\\n1. **Dependency Injection (DI):**\\n\\nDependency Injection is a design pattern that allows us to eliminate hard-coded dependencies and make our applications loosely coupled, extendable, and maintainable. In Ocean Spring Framework, DI is achieved using the `@Inject` annotation.\\n\\nHere's a simple example:\\n\\n```java\\npublic class ServiceA {\\n    private final ServiceB serviceB;\\n\\n    @Inject\\n    public ServiceA(ServiceB serviceB) {\\n        this.serviceB = serviceB;\\n    }\\n\\n    // ...\\n}\\n\\npublic class ServiceB {\\n    // ...\\n}\\n```\\n\\nIn this example, `ServiceA` depends on `ServiceB`. Instead of creating an instance of `ServiceB` within `ServiceA`, we inject it through its constructor. This way, we can easily swap implementations of `ServiceB` without changing the code in `ServiceA`.\\n\\n2. **Circular Dependency:**\\n\\nCircular dependency occurs when two or more classes depend on each other, either directly or indirectly. This situation is generally considered to be a code smell and can lead to various issues, such as difficulty in testing, increased coupling, and runtime errors.\\n\\nHere's an example of circular dependency:\\n\\n```java\\npublic class ServiceA {\\n    private final ServiceB serviceB;\\n\\n    @Inject\\n    public ServiceA(ServiceB serviceB) {\\n        this.serviceB = serviceB;\\n    }\\n\\n    public void doSomething() {\\n        serviceB.doSomethingElse();\\n    }\\n}\\n\\npublic class ServiceB {\\n    private final ServiceA serviceA;\\n\\n    @Inject\\n    public ServiceB(ServiceA serviceA) {\\n        this.serviceA = serviceA;\\n    }\\n\\n    public void doSomethingElse() {\\n        serviceA.doSomething();\\n    }\\n}\\n```\\n\\nIn this case, `ServiceA` depends on `ServiceB`, and `ServiceB` depends on `ServiceA`. This creates a circular dependency.\\n\\n**Handling Circular Dependencies:**\\n\\nOcean Spring Framework provides several ways to handle circular dependencies:\\n\\n- **Use Interfaces:** You can introduce interfaces and inject the interfaces instead of the concrete classes. This way, the circular dependency is broken because the classes are not dependent on each other's concrete implementations.\\n\\n- **Use Provider Classes:** You can create a provider class that manages the creation and lifecycle of the objects with circular dependencies.\\n\\n- **Use Qualifiers:** If the circular dependency is due to having two beans with the same type, you can use qualifiers to distinguish between them.\\n\\n- **Use @Lazy:** The `@Lazy` annotation can be used to delay the creation of a bean until it is actually needed, which can help in resolving circular dependencies in some cases.\\n\\nRemember, while circular dependencies can sometimes be unavoidable, they should be used sparingly and only when absolutely necessary. Always strive for loose coupling and high cohesion in your design.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 644, 'prompt_tokens': 115, 'total_tokens': 759}, 'model_name': 'ibm/granite-3-2-8b-instruct', 'system_fingerprint': '', 'finish_reason': 'stop'}, id='chatcmpl-f1b90d0cd9251da572468a5f1864fc54', usage_metadata={'input_tokens': 115, 'output_tokens': 644, 'total_tokens': 759})\n"
     ]
    }
   ],
   "source": [
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 644,\n",
       "  'prompt_tokens': 115,\n",
       "  'total_tokens': 759},\n",
       " 'model_name': 'ibm/granite-3-2-8b-instruct',\n",
       " 'system_fingerprint': '',\n",
       " 'finish_reason': 'stop'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "### In simple terms , Tools are python functions binded with agents , which are called by agents , if reasoning process demands to , in order to get the best output for the user prompt\n",
    "\n",
    "Lets define a simple function that returns multiplication of 2 numbers when 2 numbers are passed as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a:int , b:int):\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's bind multiply tool with llm which we configured above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools=llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's query llm and see if it uses available tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-7a7e4ed09e454f37ae5e1f76563c355f', 'type': 'function', 'function': {'name': 'multiply', 'arguments': '{\"a\": 2, \"b\": 3}'}}]}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 230, 'total_tokens': 257}, 'model_name': 'ibm/granite-3-2-8b-instruct', 'system_fingerprint': '', 'finish_reason': 'tool_calls'}, id='chatcmpl-4bf7339be529a9bd5f12c0512f158fe4', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'chatcmpl-tool-7a7e4ed09e454f37ae5e1f76563c355f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 230, 'output_tokens': 27, 'total_tokens': 257})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call=llm_with_tools.invoke([HumanMessage(content=\"what is 2 multiplied by 3\",name=\"jas\")])\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using messages as graph state\n",
    "\n",
    " 1. lets define our state MessageState\n",
    " 2. lets keep messages as list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages:list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducers\n",
    "\n",
    "Now, we have a minor problem!\n",
    "\n",
    "As our graph runs, we want to append messages to our `messages` state key.\n",
    "\n",
    "But, as we discussed, each node [will also override](#) the prior state value.\n",
    "\n",
    "[Reducer functions](#) address this.\n",
    "\n",
    "They allow us to specify how state updates are performed.\n",
    "\n",
    "If no reducer function is explicitly specified, then it is assumed that all updates to that key should *override it*.\n",
    "\n",
    "Since we want to append messages, we can use a pre-built `add_messages` reducer!\n",
    "\n",
    "This ensures that state updates you send to the graph are appended to the existing list of messages.\n",
    "\n",
    "We annotate (via `Annotated`) our key with a reducer function as metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages:Annotated[list[AnyMessage],add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUR graph\n",
    "lets use MessageState that we defined above with a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image , display\n",
    "from langgraph.graph import START,END,StateGraph\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    pass\n",
    "\n",
    "#Node\n",
    "def tool_calling_LLM(state:MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "builder=StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\",tool_calling_LLM)\n",
    "builder.add_edge(START,\"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\",END)\n",
    "graph=builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='hello!', additional_kwargs={}, response_metadata={}, id='83b1564f-674e-4c91-a069-b199a81b1a91'),\n",
       "  AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 223, 'total_tokens': 233}, 'model_name': 'ibm/granite-3-2-8b-instruct', 'system_fingerprint': '', 'finish_reason': 'stop'}, id='chatcmpl-e3c397edd3e5e795761be9521764f8fc', usage_metadata={'input_tokens': 223, 'output_tokens': 10, 'total_tokens': 233})]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages=graph.invoke({\"messages\":HumanMessage(content=\"hello!\")})\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### observe that our LLM responded without using any tool\n",
    "\n",
    "### Now lets give a human message , will see if LLM uses tool or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is answer when 2 is multiplied by 3?', additional_kwargs={}, response_metadata={}, id='5d175714-e822-4032-8d37-f71fac3756b6'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-d1ff90332c41415ca26d32eaeb648248', 'type': 'function', 'function': {'name': 'multiply', 'arguments': '{\"a\": 2, \"b\": 3}'}}]}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 234, 'total_tokens': 261}, 'model_name': 'ibm/granite-3-2-8b-instruct', 'system_fingerprint': '', 'finish_reason': 'tool_calls'}, id='chatcmpl-dc794d20d3135bb03d315c8c351b6c39', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'chatcmpl-tool-d1ff90332c41415ca26d32eaeb648248', 'type': 'tool_call'}], usage_metadata={'input_tokens': 234, 'output_tokens': 27, 'total_tokens': 261})]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages=graph.invoke({\"messages\":HumanMessage(content=\"what is answer when 2 is multiplied by 3?\")})\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It can be seen in AIMessage that it made a tool call named \"multiply\"\n",
    "## yayy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='how are you!', additional_kwargs={}, response_metadata={}, id='c9e26150-483b-4632-97d0-9388c3b5e693'),\n",
       "  AIMessage(content=\"I'm an artificial intelligence, so I don't have feelings, but I'm here and ready to assist you! How can I help you today?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 225, 'total_tokens': 259}, 'model_name': 'ibm/granite-3-2-8b-instruct', 'system_fingerprint': '', 'finish_reason': 'stop'}, id='chatcmpl-3a927f4aaf2bba4619169b2396bd9592', usage_metadata={'input_tokens': 225, 'output_tokens': 34, 'total_tokens': 259})]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages=graph.invoke({\"messages\" : HumanMessage(content=\"how are you!\")})\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### our LLM now not using tool!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
